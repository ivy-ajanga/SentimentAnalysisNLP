{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e2376a2",
   "metadata": {},
   "source": [
    "# Sentiment Analysis for Movie Reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41be42",
   "metadata": {},
   "source": [
    "The project involves building a sentiment analysis model using the IMDB movie review dataset. The goal is to classify movie reviews as either positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a4ff45",
   "metadata": {},
   "source": [
    "Tools Needed: Python programming language, Jupyter Notebook, Scikit-learn library, NLTK library and IMDB movie review dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd77b9",
   "metadata": {},
   "source": [
    "Step 1: Import Libraries and Load Data In this step, we will import the necessary libraries and load the IMDB movie review dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1718852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('imdb_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763ea22",
   "metadata": {},
   "source": [
    "Step 2: Data cleaning and preprocessing\n",
    "Before we start building the model, we need to preprocess the data by removing unnecessary information, converting the text to lowercase, removing stopwords, and performing stemming or lemmatization. Run the following code to perform these preprocessing steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76352aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ivyajanga/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = [stemmer.stem(word) for word in text if word not in stopwords]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "data['review'] = data['review'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8eb6b4",
   "metadata": {},
   "source": [
    "Step 3: Split the dataset into training and testing sets\n",
    "We will split the dataset into training and testing sets, with 80% of the data used for training and 20% used for testing. Run the following code to split the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652ff384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data['review']\n",
    "y = data['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c711c",
   "metadata": {},
   "source": [
    "Step 4: Vectorize the text\n",
    "We need to convert the text into a numerical format that can be used by machine learning algorithms. We will use the \"CountVectorizer\" class from the \"sklearn.feature_extraction.text\" module to convert the text into a bag-of-words representation. Run the following code to vectorize the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffdca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e26ef",
   "metadata": {},
   "source": [
    "Step 5: Train the model\n",
    "We will use the \"LogisticRegression\" class from the \"sklearn.linear_model\" module to train the sentiment analysis model. Run the following code to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fa947ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivyajanga/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c6d874",
   "metadata": {},
   "source": [
    "Step 7: Evaluate the model\n",
    "We will use the accuracy score to evaluate the performance of the model on the test set. Run the following code to evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d34ed5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8821\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b2882c",
   "metadata": {},
   "source": [
    "Findings\n",
    "The sentiment analysis model achieved an accuracy of around 88.21%, which is a good\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
